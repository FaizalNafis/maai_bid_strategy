{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\OneDrive\\\\UCL\\\\term_2\\\\temp_git\\\\maai_bid_strategy'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import sklearn\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, classification_report, log_loss, r2_score, accuracy_score\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = pickle.load(open( \"resampled_2\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory(df):\n",
    "    print(\"Memory usage of the dataframe is {:.2f} MB\".format(\n",
    "        df.memory_usage().sum() / 1024**2))\n",
    "    \n",
    "    \n",
    "def entropy(df, base = 2):\n",
    "    \"\"\" Calculate the entropy for every column in a df\"\"\"\n",
    "    \n",
    "    entropy = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        prob = df[column].value_counts(normalize=True, sort=False)\n",
    "        \n",
    "        entropy[column] = -(prob * np.log(prob)/np.log(base)).sum()\n",
    "        \n",
    "    return pd.Series(entropy).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_drive = False\n",
    "convert = False\n",
    "path = 'C:/Users/User/OneDrive/UCL/term_2/git/maai_bid_strategy'\n",
    "\n",
    "if(google_drive):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    train = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/train.csv')\n",
    "    validation = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/validation.csv')\n",
    "    test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/test.csv')\n",
    "    \n",
    "elif(convert):\n",
    "    train = pd.read_csv(path+'/we_data/train.csv')\n",
    "    train.to_hdf('train.h5', 'train')\n",
    "    \n",
    "else:\n",
    "    train = pd.read_hdf('train.h5', 'train')\n",
    "#     validation = pd.read_csv('validation.h5','validation')\n",
    "    validation = pd.read_csv(path+'/we_data/validation.csv')\n",
    "    test = pd.read_csv(path+'/we_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2430981, 25), (303375, 22), (303925, 25))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline average CTR 0.03691%\n"
     ]
    }
   ],
   "source": [
    "no_click,click = train['click'].value_counts().values\n",
    "print('Baseline average CTR {:.5%}'.format(click/(no_click+no_click)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_featuresize_one_hot_encoding(df):\n",
    "    \"\"\"Calcualte the number of featuers nessecary for one hot encoding\"\"\"\n",
    "\n",
    "    total_features = 0\n",
    "    for column in df.columns:\n",
    "        total_features += len(df[column].unique())\n",
    "\n",
    "    print('Rougly {:,} features in the feature space'.format(total_features))\n",
    "\n",
    "    return total_features\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\" Enrich dataframe with additional features\n",
    "    \n",
    "        Note that all fields that are joined are slightly redundent when\n",
    "        implementing more sophisticated models like NN that could pick up\n",
    "        on these feature combinations, however, it can improve the perforamce\n",
    "        of simpler models such as logisitc regression\"\"\"\n",
    "\n",
    "    # split user agent into os and browser\n",
    "    df['os'], df['browser'] = df['useragent'].str.split('_').str\n",
    "\n",
    "    # apple users\n",
    "    df['apple'] = df['useragent'].str.match(r'(ios)|(mac)').astype(np.uint8)\n",
    "\n",
    "    # deterime mobile devivce or not\n",
    "    df['mobieldevice'] = df['useragent'].str.match(r'(ios)|(android)').astype(\n",
    "        np.uint8)\n",
    "\n",
    "    # hour per day\n",
    "    df['weekdayhour'] = df['weekday'].astype(str) + '_' + df['hour'].astype(\n",
    "        str)\n",
    "\n",
    "    # bin hours into time of day\n",
    "    df['timeofday'] = pd.cut(\n",
    "        df['hour'].astype(int),\n",
    "        4,\n",
    "        labels=[\"night\", \"morning\", \"afternoon\", \"evening\"])\n",
    "\n",
    "    # bin ad surface size categories\n",
    "    min_ad = min(df['slotwidth'] * df['slotheight']) - 1\n",
    "    max_ad = max(df['slotwidth'] * df['slotheight'])\n",
    "\n",
    "    ad_bins = pd.IntervalIndex.from_breaks(\n",
    "        [min_ad, 65520, 75000, 90000, max_ad])\n",
    "\n",
    "    replace, with_ = [\n",
    "        pd.Interval(min_ad, 65520),\n",
    "        pd.Interval(65520, 75000),\n",
    "        pd.Interval(75000, 90000),\n",
    "        pd.Interval(90000, max_ad)\n",
    "    ], ['small', 'medium', 'large', 'x-large']\n",
    "\n",
    "    df['adsize'] = pd.cut(\n",
    "        df['slotwidth'] * df['slotheight'], bins=ad_bins).replace(\n",
    "            replace, with_)\n",
    "\n",
    "    # bin slot price into categories\n",
    "    price_bins = pd.IntervalIndex.from_breaks(\n",
    "        [min(df['slotprice']), 10, 50, 100,\n",
    "         max(df['slotprice'])],\n",
    "        closed='left')\n",
    "    replace, with_ = [\n",
    "        pd.Interval(min(df['slotprice']), 10, closed='left'),\n",
    "        pd.Interval(10, 50, closed='left'),\n",
    "        pd.Interval(50, 100, closed='left'),\n",
    "        pd.Interval(100, max(df['slotprice']), closed='left')\n",
    "    ], ['1', '2', '3', '4']\n",
    "\n",
    "    df['slotprice'] = pd.cut(\n",
    "        df['slotprice'], bins=price_bins).replace(replace, with_)\n",
    "\n",
    "    # ad size category and visability\n",
    "    df['advisabilitysize'] = df['slotvisibility'].astype(\n",
    "        str) + '_' + df['adsize'].astype(str)\n",
    "\n",
    "    return df.drop(columns=['slotwidth', 'slotheight'])\n",
    "\n",
    "\n",
    "def pre_process_one_hot_encoding(df):\n",
    "    \"\"\" Preprocess the dataframe for one hot encoding\n",
    "    \n",
    "        - Split the filed user tags and binary encode\n",
    "        - Convert numerical categories into strings \n",
    "        \"\"\"\n",
    "\n",
    "    # convert numerical categories into strings as a quick hack\n",
    "    # for one hot encoding to work properly on numerical categories\n",
    "    df['weekday'] = df['weekday'].astype(str)\n",
    "    df['hour'] = df['hour'].astype(str)\n",
    "    df['region'] = df['region'].astype(str)\n",
    "    df['city'] = df['city'].astype(str)\n",
    "    df['adexchange'] = df['adexchange'].astype(str)\n",
    "    df['advertiser'] = df['advertiser'].astype(str)\n",
    "\n",
    "    # already processed and not found in columns\n",
    "    if ('usertag' not in df.columns):\n",
    "        return df\n",
    "\n",
    "    df['usertag'] = df['usertag'].astype(str)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    df = df.join(\n",
    "        pd.DataFrame(\n",
    "            mlb.fit_transform(df['usertag'].str.split(',')),\n",
    "            columns='usertag_' + mlb.classes_,\n",
    "            index=df.index))\n",
    "\n",
    "    # drop the usertag column\n",
    "    df = df.drop(columns='usertag')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_colums(df):\n",
    "\n",
    "    # Remove uniuqe and meaningless featuers that are not know a pirori\n",
    "    columns = ['bidprice', 'urlid', 'bidid']\n",
    "\n",
    "    # remove some very sparse fields to reduce featuers (highest entropy)\n",
    "    columns.extend(['userid', 'url', 'domain', 'slotid', 'IP'])\n",
    "\n",
    "    # only remove columns that are in the df\n",
    "    columns = [column for column in columns if column in df.columns]\n",
    "\n",
    "    return df.drop(columns=columns)\n",
    "\n",
    "\n",
    "def add_missing_colums(df, columns, sort_columns=True):\n",
    "    \"\"\" Due to the feature engineering there is a chance a discrapency occurs\n",
    "        between \n",
    "        \"\"\"\n",
    "\n",
    "    missing = [x for x in columns if x not in df.columns]\n",
    "\n",
    "    for x in missing:\n",
    "        print('Adding {}'.format(x))\n",
    "        df[x] = 0\n",
    "\n",
    "    if (sort_columns):\n",
    "        return df[sorted(df.columns)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcluate_num_impressions(df, grouping = False):\n",
    "    imp = {}\n",
    "    \n",
    "    if(grouping):\n",
    "        imp = df.groupby(grouping).size().to_dict()\n",
    "            \n",
    "    else:\n",
    "        imp = len(df)\n",
    "    \n",
    "    print(imp)\n",
    "    return imp\n",
    "    \n",
    "\n",
    "\n",
    "def calcluate_num_clicks(df, grouping = False):\n",
    "    clicks = {}\n",
    "    \n",
    "    if(grouping):\n",
    "        for index, group in df.groupby(grouping):\n",
    "            clicks[index] = np.sum(group['click'])\n",
    "            \n",
    "    else:\n",
    "        clicks = np.sum(df['click'])\n",
    "    \n",
    "    print(clicks)\n",
    "    return clicks\n",
    "    \n",
    "\n",
    "def calcluate_ctr(df, grouping = False):\n",
    "    ctr = {}\n",
    "    \n",
    "    if(grouping):\n",
    "        for index, group in df.groupby(grouping):\n",
    "            ctr[index] = np.average(group['click']) * 100\n",
    "            \n",
    "    else:\n",
    "        ctr = np.average(df['click']) * 100\n",
    "    \n",
    "    print(ctr)\n",
    "    return ctr\n",
    "    \n",
    "    \n",
    "def average_cost_per_mille(df, grouping = False):\n",
    "    cpm = {}\n",
    "    \n",
    "    if(grouping):\n",
    "        cpm = df.groupby('weekday').agg({'payprice': np.mean}).to_dict()['payprice']\n",
    "        \n",
    "    else:\n",
    "        cpm = np.mean(df['payprice'])\n",
    "        \n",
    "    print(cpm)\n",
    "    return cpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 635 ms\n",
      "Wall time: 1.23 s\n",
      "Wall time: 1min 10s\n",
      "Wall time: 19 s\n",
      "Wall time: 33 s\n",
      "Wall time: 517 ms\n",
      "Wall time: 198 ms\n",
      "Wall time: 2.33 s\n",
      "Wall time: 11 s\n",
      "Wall time: 2.68 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "other fillna strategies for adexchange should be considered at some point!\n",
    "\n",
    "the only columns that contain a lot of missing values that are used in the final \n",
    "analysis are adexchange and usertag. Different strategies have been considered but \n",
    "it was deemed to be the most informative to assign a 'unknown' class which is easely\n",
    "achieved trhough filling 0's since they do not occur in the dataset\n",
    "\n",
    "\"\"\"\n",
    "%time train = drop_colums(train)\n",
    "%time train = train.fillna(0)\n",
    "%time train = feature_engineering(train)\n",
    "%time train = pre_process_one_hot_encoding(train)\n",
    "%time train = pd.get_dummies(train)\n",
    "\n",
    "%time test = drop_colums(test)\n",
    "%time test = test.fillna(0)\n",
    "%time test = pre_process_one_hot_encoding(test)\n",
    "%time test = feature_engineering(test)\n",
    "%time test = pd.get_dummies(test)\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 854 ms\n",
      "Wall time: 134 ms\n",
      "Wall time: 8.77 s\n",
      "Wall time: 2.25 s\n",
      "Wall time: 2.58 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%time validation = drop_colums(validation)\n",
    "%time validation = validation.fillna(0)\n",
    "%time validation = feature_engineering(validation)\n",
    "%time validation = pre_process_one_hot_encoding(validation)\n",
    "%time validation = pd.get_dummies(validation)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 s\n",
      "Adding useragent_android_ie\n",
      "Adding useragent_android_maxthon\n",
      "Adding useragent_other_firefox\n",
      "Adding creative_7324\n",
      "Adding creative_7332\n",
      "Adding useragent_android_maxthon\n",
      "Adding creative_7332\n",
      "Wall time: 1.24 s\n",
      "Adding click\n",
      "Adding payprice\n",
      "Adding useragent_linux_ie\n",
      "Adding useragent_mac_maxthon\n",
      "Adding useragent_mac_sogou\n",
      "Adding creative_7327\n",
      "Adding click\n",
      "Adding payprice\n",
      "Adding useragent_android_ie\n",
      "Adding useragent_linux_ie\n",
      "Adding useragent_mac_maxthon\n",
      "Adding useragent_mac_sogou\n",
      "Adding useragent_other_firefox\n",
      "Adding creative_7324\n",
      "Adding creative_7327\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the featuere engineering can construct columns that do not occur in other sets \n",
    "# this adds the columns of the joined colomuns\n",
    "joined_colums = [item for slist in [validation.columns, train.columns, test.columns] for item in slist]\n",
    "\n",
    "%time train = add_missing_colums(train,joined_colums)\n",
    "%time validation = add_missing_colums(validation,joined_colums)\n",
    "%time test = add_missing_colums(test,joined_colums)\n",
    "\n",
    "\n",
    "# this list should be empty!!\n",
    "[x for x in validation.columns if x not in train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train.to_hdf('preprocessed.h5', 'train')\n",
    "validation.to_hdf('preprocessed.h5', 'validation')\n",
    "test.to_hdf('preprocessed.h5', 'test')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2430981, 965), (303375, 965), (303925, 965))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2430981, 965), (303925, 965))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_hdf('preprocessed.h5', 'train')\n",
    "validation = pd.read_hdf('preprocessed.h5', 'validation')\n",
    "test = pd.read_hdf('preprocessed.h5', 'test')\n",
    "\n",
    "train.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Grid Search CV Function for Selected model\n",
    "def model_CVGridSearch(model, param_grid, n_jobs, rs, scoring):\n",
    "    \n",
    "    estimator = model()\n",
    "    cv = [(slice(None), slice(None))]\n",
    "    classifier = GridSearchCV(estimator=estimator, cv=cv, refit=True,\n",
    "                              param_grid=param_grid, n_jobs=n_jobs, scoring=scoring)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Best Estimator learned through GridSearch for \" + str(model))\n",
    "    print(classifier.best_estimator_)\n",
    "    \n",
    "    return cv, classifier.best_estimator_, classifier.best_params_, classifier.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on AUC as log-loss shouldn't be used to evaluate KNN models [https://medium.com/@bengikoseoglu/why-log-loss-metric-shouldnt-be-used-to-evaluate-nearest-neighbour-classification-1fe314f460a2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 21\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Wall time: 13h 31min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 9\n",
    "k_range = [5,9,17,20,25]\n",
    "weight_options = [\"uniform\"]\n",
    "\n",
    "scoring = 'accuracy'\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_jobs = -1\n",
    "knn_rs = seed\n",
    "\n",
    "knn_cv, knn_best, knn_params, knn_cvResults = model_CVGridSearch(model = KNeighborsClassifier\n",
    "                                                                 ,param_grid = param_grid,n_jobs= knn_jobs, rs=knn_rs, scoring=scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([394.97855902, 402.54831052, 399.01326299, 405.49282765,\n",
       "        403.12892032]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0.]),\n",
       " 'mean_score_time': array([18864.36063218, 20559.63835478, 23245.77737117, 23942.0502007 ,\n",
       "        25034.18642879]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'param_n_neighbors': masked_array(data=[5, 9, 17, 20, 25],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'uniform', 'uniform', 'uniform', 'uniform'],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 20, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 25, 'weights': 'uniform'}],\n",
       " 'split0_test_score': array([0.86041483, 0.77691466, 0.69031126, 0.68163557, 0.64992926]),\n",
       " 'mean_test_score': array([0.86041483, 0.77691466, 0.69031126, 0.68163557, 0.64992926]),\n",
       " 'std_test_score': array([0., 0., 0., 0., 0.]),\n",
       " 'rank_test_score': array([1, 2, 3, 4, 5]),\n",
       " 'split0_train_score': array([0.86041483, 0.77691466, 0.69031126, 0.68163557, 0.64992926]),\n",
       " 'mean_train_score': array([0.86041483, 0.77691466, 0.69031126, 0.68163557, 0.64992926]),\n",
       " 'std_train_score': array([0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cvResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   no click       1.00      0.61      1.00      0.76      0.78      0.59     24988\n",
      "      click       0.72      1.00      0.61      0.84      0.78      0.64     24961\n",
      "\n",
      "avg / total       0.86      0.81      0.81      0.80      0.78      0.61     49949\n",
      "\n",
      "Balanced accuracy score: 80.691%\n",
      "ROC AUC score 0.806907120714205\n",
      "done\n",
      "Wall time: 1h 13min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_hat = knn_best.predict(X_test)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_hat, target_names=['no click', 'click']))\n",
    "print(\"Balanaced accuracy score: {:.3%}\".format(balanced_accuracy_score(y_test, y_hat) ))\n",
    "print('ROC AUC score {}'.format(roc_auc_score(y_test, y_hat)))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## ReFit Best model on all resampled dataset\n",
    "\n",
    "knn_best.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_best = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                                metric_params=None, n_jobs=-1, n_neighbors=5, \n",
    "                                p=2, weights='uniform')\n",
    "\n",
    "knn_best.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_validate_true = validation['click'].values\n",
    "X_validate = validation.drop(columns=['click', 'payprice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   no click       1.00      0.81      0.53      0.89      0.66      0.44    303723\n",
      "      click       0.00      0.53      0.81      0.00      0.66      0.42       202\n",
      "\n",
      "avg / total       1.00      0.81      0.53      0.89      0.66      0.44    303925\n",
      "\n",
      "ROC AUC score 0.6698290469400157\n",
      "done\n",
      "Wall time: 3h 22min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_validate_hat = knn_best.predict(X_validate)\n",
    "\n",
    "print(classification_report_imbalanced(y_validate_true, y_validate_hat, target_names=['no click', 'click']))\n",
    "print('ROC AUC score {}'.format(roc_auc_score(y_validate_true, y_validate_hat)))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 20min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_validate_prob = knn_best.predict_proba(X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal base bid based on pCTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "payprice = validation['payprice']\n",
    "clicks = validation['click']\n",
    "\n",
    "# VERIFY THAT THE pCTR INDEED IS EQUAL TO THE PROB OF CLICK == 1\n",
    "pCTR = y_validate_prob[:, 1]\n",
    "\n",
    "no_click, click = np.bincount(y_validate_true)\n",
    "avgCTR = click / (no_click + click)\n",
    "\n",
    "bid_strategy = lambda base_bid: base_bid * (pCTR / avgCTR)\n",
    "\n",
    "bid_range = np.arange(3.4, 3.8, 0.02)\n",
    "bid_range_wide = np.arange(1, 5, .5)\n",
    "bid_range = np.concatenate((bid_range, bid_range_wide), axis=0)\n",
    "\n",
    "# bid_range = np.arange(1.7, 1.9, 0.01)\n",
    "statistics = {}\n",
    "\n",
    "# find optimal base_bid\n",
    "for base_bid in tqdm(bid_range):\n",
    "    \n",
    "    budget_remaining = 6250*1000\n",
    "    \n",
    "    statistics[base_bid] = {\n",
    "        'impressions':0,\n",
    "        'spend': 0,\n",
    "        'clicks': 0\n",
    "    }\n",
    "    \n",
    "    # list of bids for all ad requests\n",
    "    bids = bid_strategy(base_bid)\n",
    "    \n",
    "    # loop through all bids for every ad request\n",
    "    for i in range(len(bids)):    \n",
    "        second_highest_bid = payprice[i]\n",
    "        \n",
    "        won = bids[i] >= second_highest_bid and second_highest_bid <= budget_remaining\n",
    "        \n",
    "        if(won):\n",
    "            statistics[base_bid]['impressions'] += 1\n",
    "            statistics[base_bid]['spend'] += second_highest_bid\n",
    "            statistics[base_bid]['clicks'] += clicks[i]\n",
    "            \n",
    "            # subtract current bid from budget \n",
    "            budget_remaining -= second_highest_bid\n",
    "            \n",
    "statistics = pd.DataFrame(statistics).T\n",
    "statistics['CTR'] = statistics['clicks'] / statistics['impressions']\n",
    "statistics['aCPM'] = statistics['spend'] / statistics['impressions'] \n",
    "statistics['aCPC'] = (statistics['spend']/1000) / statistics['clicks']\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.sort_values('clicks', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pCTR to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_test = test.drop(columns=['click', 'payprice'])\n",
    "y_test_prob = knn_best.predict_proba(X_test)\n",
    "avgCTR = click / (no_click + click)\n",
    "\n",
    "base_bid = 3.62\n",
    "pCTR = y_test_prob[:, 1]\n",
    "\n",
    "\n",
    "bid_strategy = lambda base_bid: (base_bid * (pCTR / avgCTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bid id's\n",
    "\n",
    "google_drive = False\n",
    "\n",
    "if(google_drive):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    test_raw = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/test.csv')\n",
    "    \n",
    "else:\n",
    "    test_raw = pd.read_csv('../we_data/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to file\n",
    "df_bids = pd.DataFrame(np.round(bid_strategy(base_bid),1), index=test_raw['bidid'].values, columns=['bidprice'])\n",
    "df_bids.index.name = 'bidid'\n",
    "df_bids = df_bids.reset_index()\n",
    "\n",
    "df_bids.to_csv('bid_attemnt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_validate_prob = knn_best.predict_proba(X_validate)\n",
    "# print('Log loss {}'.format(log_loss(y_validate_true, y_validate_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# uni_neigh = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "#                                  p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "# uni_neigh.fit(X_train,y_train)\n",
    "\n",
    "# dist_neigh = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=30, \n",
    "#                                  p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "# dist_neigh.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   no click       1.00      0.71      1.00      0.83      0.84      0.69     25101\n",
      "      click       0.77      1.00      0.71      0.87      0.84      0.73     24848\n",
      "\n",
      "avg / total       0.89      0.85      0.86      0.85      0.84      0.71     49949\n",
      "\n",
      "Balanced accuracy score: 85.524%\n",
      "ROC AUC score 0.8552415658639931\n",
      "done\n",
      "Wall time: 16min 36s\n",
      "Wall time: 16min 36s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# y_hat = dist_neigh.predict(X_test)\n",
    "\n",
    "# print(classification_report_imbalanced(y_test, y_hat, target_names=['no click', 'click']))\n",
    "# print(\"Balanced accuracy score: {:.3%}\".format(balanced_accuracy_score(y_test, y_hat) ))\n",
    "# print('ROC AUC score {}'.format(roc_auc_score(y_test, y_hat)))\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   no click       1.00      0.71      1.00      0.83      0.84      0.69     25101\n",
      "      click       0.77      1.00      0.71      0.87      0.84      0.73     24848\n",
      "\n",
      "avg / total       0.89      0.85      0.85      0.85      0.84      0.71     49949\n",
      "\n",
      "Balanced accuracy score: 85.399%\n",
      "ROC AUC score 0.8539874470564548\n",
      "done\n",
      "Wall time: 17min\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# y_hat = uni_neigh.predict(X_test)\n",
    "\n",
    "# print(classification_report_imbalanced(y_test, y_hat, target_names=['no click', 'click']))\n",
    "# print(\"Balanced accuracy score: {:.3%}\".format(balanced_accuracy_score(y_test, y_hat) ))\n",
    "# print('ROC AUC score {}'.format(roc_auc_score(y_test, y_hat)))\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_validate_hat = dist_neigh.predict(X_validate)\n",
    "# print(classification_report_imbalanced(y_validate_true, y_validate_hat, target_names=['no click', 'click']))\n",
    "# print('ROC AUC score {}'.format(roc_auc_score(y_validate_true, y_validate_hat)))\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_validate_hat = uni_neigh.predict(X_validate)\n",
    "# print(classification_report_imbalanced(y_validate_true, y_validate_hat, target_names=['no click', 'click']))\n",
    "# print('ROC AUC score {}'.format(roc_auc_score(y_validate_true, y_validate_hat)))\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_validate_prob = dist_neigh.predict_proba(X_validate)\n",
    "# print('Log loss {}'.format(log_loss(y_validate_true, y_validate_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k 1 Log loss 4.133857136271352\n",
      "For k 1 ROC AUC 0.6457579344623648\n",
      "For k 5 Log loss 3.5690849487313066\n",
      "For k 5 ROC AUC 0.6941830269197542\n",
      "For k 9 Log loss 3.285574634612604\n",
      "For k 9 ROC AUC 0.7004919281746529\n",
      "Wall time: 33min 59s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# for k in [1,5,9,17,20,25]:\n",
    "\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "#                                  p=2, metric='minkowski', metric_params=None, n_jobs=-1) \n",
    "#     neigh.fit(X_train, y_train)\n",
    "    \n",
    "#     y_validate_prob = neigh.predict_proba(X_validate)\n",
    "#     print('For k {} Log loss {}'.format(k, log_loss(y_validate_true, y_validate_prob)))\n",
    "#     print('For k {} ROC AUC {}'.format(k, roc_auc_score(y_validate_true, y_validate_prob[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k 11 Log loss 3.169505887897813\n",
      "For k 11 ROC AUC 0.7041729056599025\n",
      "For k 15 Log loss 2.9522700159010613\n",
      "For k 15 ROC AUC 0.7121898021135269\n",
      "For k 17 Log loss 2.8635431959821136\n",
      "For k 17 ROC AUC 0.7127802551197722\n",
      "For k 19 Log loss 2.781256169702471\n",
      "For k 19 ROC AUC 0.7143356229717261\n"
     ]
    }
   ],
   "source": [
    "# for k in [11,15,17,19]:\n",
    "\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "#                                  p=2, metric='minkowski', metric_params=None, n_jobs=-1) \n",
    "#     neigh.fit(X_train, y_train)\n",
    "    \n",
    "#     y_validate_prob = neigh.predict_proba(X_validate)\n",
    "#     print('For k {} Log loss {}'.format(k, log_loss(y_validate_true, y_validate_prob)))\n",
    "#     print('For k {} ROC AUC {}'.format(k, roc_auc_score(y_validate_true, y_validate_prob[:,1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
